---
title: ğŸ™‡ Thompson Sampling with Time-Varying Reward for Contextual Bandits
summary: International Conference on Database Systems for Advanced Applications (DASFAA 2023)
date: 2023-03-20
authors:
  - Cairong Yan, Hualu Xu, Haixia Han, Yanting Zhang, Zijian Wang
# tags:
#   - 
#   - 
image:
  caption: 'Image credit: [**Unsplash**](https://unsplash.com)'
---
### ğŸŒŸ Abstract
Contextual bandits efficiently solve the exploration and exploitation (EE) problem in online recommendation tasks. Most existing contextual bandit algorithms utilize a fixed reward mechanism, which makes it difficult to accurately capture the preference changes of users in non-stationary environments, thus affecting recommendation performance. In this paper, we formalize the online recommendation task as a contextual bandit problem and propose a Thompson sampling algorithm with time-varying reward (TV-TS) that captures user preference changes from three perspectives: (1) forgetting past preferences based on a functional decay method while capturing possible periodic demands, (2) mining fine-grained preference changes from multi-behavioral implicit feedback, and (3) iterating the reward weights adaptively. We also provide theoretical regret analysis to demonstrate the sublinearity of the algorithm. Extensive empirical experiments on two real-world datasets show that our proposed algorithm outperforms state-of-the-art time-varying bandit algorithms. Furthermore, the designed reward mechanism can be flexibly configured to other bandit algorithms to improve them.

![å›¾](./xuhualu2.png "Fig. The workflow of a contextual bandit configured with TV-RM.")
### ğŸŒŸ Full Paper
If you want to read the full paper, plese click the following buttonğŸ‘‡ğŸ»

Paper PDF ğŸ‘‰ï¼š<a href="https://link.springer.com/chapter/10.1007/978-3-031-30672-3_4"><img src="../isc/pdf.png" alt="pdf" width="40"></a>

###  ğŸ™Œ Consider Citing it
If you find this work is interesting, please consider citing our work as follow:

```
@inproceedings{yan2023thompson,
  title={Thompson Sampling with Time-Varying Reward for Contextual Bandits},
  author={Yan, Cairong and Xu, Hualu and Han, Haixia and Zhang, Yanting and Wang, Zijian},
  booktitle={International Conference on Database Systems for Advanced Applications},
  pages={54--63},
  year={2023},
  organization={Springer}
}
```